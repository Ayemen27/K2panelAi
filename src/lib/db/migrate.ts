import fs from 'fs';
import path from 'path';
import pool from './postgres';

export interface MigrationResult {
  success: boolean;
  message: string;
  migrations: string[];
  errors?: string[];
}

/**
 * ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠØ¹ Migrations Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
 */
export async function migrate(): Promise<MigrationResult> {
  const results = {
    success: true,
    message: '',
    migrations: [] as string[],
    errors: [] as string[],
  };

  const client = await pool.connect();

  try {
    console.log('ğŸ”„ Starting database migration...');

    console.log('ğŸ“ Step 1: Ensuring migrations tracking table exists...');
    await client.query(`
      CREATE TABLE IF NOT EXISTS pg_migrations (
        id SERIAL PRIMARY KEY,
        name VARCHAR(255) UNIQUE NOT NULL,
        executed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
      );
    `);
    console.log('âœ… Migrations tracking table ready');

    console.log('ğŸ“ Step 2: Checking for applied migrations...');
    const appliedMigrations = await getAppliedMigrations(client);
    console.log(`ğŸ“Š Already applied: ${appliedMigrations.size} migrations`);

    console.log('ğŸ“ Step 3: Running base schema.sql if not already applied...');
    if (!appliedMigrations.has('000_base_schema.sql')) {
      const schemaPath = path.join(process.cwd(), 'src/lib/db/schema.sql');
      const schema = fs.readFileSync(schemaPath, 'utf-8');
      await client.query(schema);
      await recordMigration(client, '000_base_schema.sql');
      results.migrations.push('000_base_schema.sql');
      console.log('âœ… Base schema created successfully');
    } else {
      console.log('â­ï¸ Base schema already applied, skipping...');
    }

    console.log('ğŸ“ Step 4: Running new migration files...');
    const migrationsDir = path.join(process.cwd(), 'database', 'migrations');
    
    if (fs.existsSync(migrationsDir)) {
      const files = fs.readdirSync(migrationsDir);
      const migrationFiles = files
        .filter(file => file.endsWith('.sql'))
        .sort();

      console.log(`ğŸ“‹ Found ${migrationFiles.length} migration files`);

      for (const file of migrationFiles) {
        if (appliedMigrations.has(file)) {
          console.log(`â­ï¸ Skipping ${file} (already applied)`);
          continue;
        }

        try {
          console.log(`ğŸ”„ Running migration: ${file}`);
          const filePath = path.join(migrationsDir, file);
          const sql = fs.readFileSync(filePath, 'utf-8');
          
          await client.query(sql);
          await recordMigration(client, file);
          results.migrations.push(file);
          console.log(`âœ… Migration ${file} completed`);
        } catch (error: any) {
          const errorMsg = `âŒ Error in ${file}: ${error.message}`;
          console.error(errorMsg);
          results.errors?.push(errorMsg);
          results.success = false;
        }
      }
    } else {
      console.log('âš ï¸ No migrations directory found, skipping...');
    }

    const newMigrations = results.migrations.filter(m => !m.includes('idempotent'));
    results.message = results.success 
      ? `âœ… Successfully ran ${newMigrations.length} new migrations (${appliedMigrations.size} already applied)`
      : `âš ï¸ Completed with errors: ${results.errors?.length || 0} failed`;
    
    console.log(results.message);
    console.log('âœ… Database migration completed successfully!');
    return results;
  } catch (error: any) {
    results.success = false;
    results.message = `âŒ Migration failed: ${error.message}`;
    results.errors?.push(error.message);
    console.error('âŒ Database migration failed:', error.message);
    console.error('ğŸ’¡ Alternative: Run manually with: psql $DATABASE_URL -f src/lib/db/schema.sql');
    throw error;
  } finally {
    client.release();
  }
}

async function getAppliedMigrations(client: any): Promise<Set<string>> {
  try {
    const result = await client.query('SELECT name FROM pg_migrations');
    return new Set(result.rows.map((row: any) => row.name));
  } catch (error) {
    console.log('âš ï¸ Migrations table not found, will be created by 000_init_migrations_table.sql');
    return new Set();
  }
}

async function recordMigration(client: any, name: string): Promise<void> {
  await client.query(
    'INSERT INTO pg_migrations (name) VALUES ($1) ON CONFLICT (name) DO NOTHING',
    [name]
  );
}

/**
 * Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
 */
export async function checkDatabase() {
  try {
    const result = await pool.query(`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public'
      ORDER BY table_name;
    `);
    
    console.log('ğŸ“Š Database tables:', result.rows.map((r: any) => r.table_name));
    return result.rows;
  } catch (error) {
    console.error('âŒ Database check failed:', error);
    throw error;
  }
}

// ØªÙ†ÙÙŠØ° Migration Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø©
if (require.main === module) {
  migrate()
    .then(() => checkDatabase())
    .then(() => process.exit(0))
    .catch((error) => {
      console.error(error);
      process.exit(1);
    });
}
